#!/usr/bin/env python

import re
import sys
from lxml import etree as xml
import requests


def parse_xml(url: str, regex_str: str, xpath_expr: str):
  """
  Parses XML content from a URL and
  extracts the desired information using
  regular expressions and XPath expressions.
  Includes detection for Atom feeds.
  """

  result = ''

  # Compile the regular expression from string
  regex = re.compile(regex_str) if regex_str != '' else None

  # Invoke a new HTTP GET request
  user_agent = 'Mozilla/5.0 (X11; Linux x86_64; rv:128.0) Gecko/20100101 Firefox/128.0'
  response = requests.get(url, headers={'User-Agent': user_agent})
  content = response.content.replace(b'\xc2\xa0', b'')
  xml_content = xml.fromstring(content)

  namespaces = None

  # TODO: Add support for other namespaces
  # Check if the XML content is an Atom feed
  if xml_content.tag == '{http://www.w3.org/2005/Atom}feed':
    namespaces = {'atom': 'http://www.w3.org/2005/Atom'}

  #  Find all the elements that were captured in the XPath expression
  elements = xml_content.xpath(xpath_expr, namespaces=namespaces)

  for e in elements:
    # If you want the text content of the element:
    # print(element.text_content())
    # If you want the HTML representation of the element:
    v = xml.tostring(e).decode()

    if regex is not None:
      matches = regex.search(v)

      if matches is not None:
        if matches.group(1) is None:
          result = matches.group(0)
        else:
          result = matches.group(1)
    else:
      result = v

  print(result)


# end of parse_xml

if __name__ == '__main__':
  # Allow the user to pass in the arguments from the command line
  parse_xml(sys.argv[1], sys.argv[2], sys.argv[3])

# How it should be used in cli
# ./scripts/parse-xml 'https://0xacab.org/leap/bitmask-vpn/-/tags?format=atom' '>([\\d.]+)<' '/atom:feed/atom:entry[1]/atom:title'
